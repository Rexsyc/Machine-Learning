{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# svm.SVC API说明： \n",
    "### 功能：\n",
    "使用SVM分类器进行模型构建    \n",
    "### 参数说明：  \n",
    "C: 误差项的惩罚系数，默认为1.0；一般为大于0的一个数字，C越大表示在训练过程中对于总误差的关注度越高，也就是说当C  越大的时候，对于训练集的表现会越好，但是有可能引发过度拟合的问题(overfiting)  \n",
    "kernel：指定SVM内部函数的类型，可选值：linear、poly、rbf、sigmoid、precomputed(基本不用，有前提要求，要求特征属性数目和样本数目一样)；默认是rbf；   \n",
    "degree：当使用多项式函数作为svm内部的函数的时候，给定多项式的项数，默认为3  \n",
    "gamma：当SVM内部使用poly、rbf、sigmoid的时候，核函数的系数值，当默认值为auto的时候，实际系数为1/n_features   \n",
    "coef0: 当核函数为poly或者sigmoid的时候，给定的独立系数，默认为0   \n",
    "probability：是否启用概率估计，默认不启动，不太建议启动   \n",
    "shrinking：是否开启收缩启发式计算，默认为True   \n",
    "tol: 模型构建收敛参数，当模型的的误差变化率小于该值的时候，结束模型构建过程，默认值:1e-3  \n",
    "cache_size：在模型构建过程中，缓存数据的最大内存大小，默认为空，单位MB   \n",
    "class_weight：给定各个类别的权重，默认为空  \n",
    "max_iter：最大迭代次数，默认-1表示不限制   \n",
    "decision_function_shape: 决策函数，可选值：ovo和ovr，默认为None；推荐使用ovr；（1.7以上版本才有）\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.使用numpy中的loadtxt读取数据文件\n",
    "*当使用numpy中的loadtxt函数导入该数据集时，假设数据类型dtype为浮点型，但是很明显第五列的数据类型并不是浮点型。*\n",
    "\n",
    "*因此我们要额外做一个工作，即通过loadtxt()函数中的converters参数将第五列通过转换函数映射成浮点类型的数据。*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 转换函数\n",
    "# 定义一个函数，将不同类别标签与数字相对应\n",
    "def iris_type(s):\n",
    "    it = {b'Iris-setosa':0, b'Iris-versicolor':1, b'Iris-virginica':2}\n",
    "    return it[s]\n",
    "# 为啥前面要加个b?\n",
    "# 报错本身的提示的意思是：字典中没有'Iris-setosa'这个键，却试图访问它。\n",
    "# 所以，鉴于这个是从文件读取的，因此，最大的可能是字符编码问题\n",
    "\n",
    "# 数据文件路径\n",
    "path = './data/iris.txt'\n",
    "data = np.loadtxt(path, dtype=float, delimiter=',', converters={4:iris_type})\n",
    "# 以上4个参数分别表示：\n",
    "# filepath ：文件路径。eg：C:/Dataset/iris.txt。\n",
    "# dtype=float ：数据类型。eg：float、str等。\n",
    "# delimiter=',' ：数据以什么分割符号分割。eg：‘，’。\n",
    "# converters={4:iris_type} ：对某一列数据（第四列）进行某种类型的转换，将数据列与转换函数进行映射的字典。eg：{1:fun}，含义是将第2列对应转换函数进行转换。\n",
    "#                          converters={4: iris_type}中“4”指的是第5列。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.将Iris分为训练集和测试集\n",
    "*1. split(数据，分割位置，轴=1（按列进行分割） or 0（按行进行分割）)。*\n",
    "\n",
    "*2. x = x[:, :2]是为方便后期画图更直观，故只取了前两列特征值向量训练。*\n",
    "  \n",
    "*3. sklearn.model_selection.train_test_split随机划分训练集与测试集。train_test_split(train_data,train_target,test_size=数字, random_state=0)*\n",
    "\n",
    "*参数解释：*\n",
    "\n",
    "*train_data：所要划分的样本特征集*\n",
    "\n",
    "*train_target：所要划分的样本结果*\n",
    "\n",
    "*test_size：样本占比，如果是整数的话就是样本的数量*\n",
    "\n",
    "*random_state：是随机数的种子。*\n",
    "\n",
    "*随机数种子：其实就是该组随机数的编号，在需要重复试验的时候，保证得到一组一样的随机数。比如你每次都填1，其他参数一样的情况下你得到的随机数组是一样的。但填0或不填，每次都会不一样。随机数的产生取决于种子，随机数和种子之间的关系遵从以下两个规则：种子不同，产生不同的随机数；种子相同，即使实例不同也产生相同的随机数。*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "x, y = np.split(data, (4,), axis=1)  # np.split 按照列（axis=1）进行分割，从第四列开始往后的作为y数据，之前的作为X数据。\n",
    "# x = x[:, :2]  # 取出前两列\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1, train_size=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.搭建模型，训练SVM分类器\n",
    "*kernel='linear'时，为线性核，C越大分类效果越好，但有可能会过拟合（defaul C=1）。*\n",
    "\n",
    "*kernel='rbf'时（default），为高斯核，gamma值越小，分类界面越连续；gamma值越大，分类界面越“散”，分类效果越好，但有可能会过拟合。*\n",
    "\n",
    "*decision_function_shape='ovr'时，为one v rest，即一个类别与其他类别进行划分*\n",
    "\n",
    "*decision_function_shape='ovo'时，为one v one，即将类别两两之间进行划分，用二分类的方法模拟多分类的结果。*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(C=0.1, kernel='linear', decision_function_shape='ovr')\n",
    "# clf = svm.SVC(C=0.8, kernel='rbf', gamma=20, decision_function_shape='ovr')\n",
    "# 开始训练\n",
    "clf.fit(x_train, y_train.ravel())  # 想一想，这里为什么要用ravel()\n",
    "# print(y_train)\n",
    "# print(y_train.ravel())\n",
    "# 调用ravel()函数将矩阵转变成一维数组（ravel()函数与flatten()的区别）\n",
    "# 两者所要实现的功能是一致的（将多维数组降为一维），\n",
    "# 两者的区别在于返回拷贝（copy）还是返回视图（view），\n",
    "# numpy.flatten() 返回一份拷贝，对拷贝所做的修改不会影响（reflects）原始矩阵，\n",
    "# 而numpy.ravel()返回的是视图（view），会影响（reflects）原始矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def show_accuracy(y_hat, y_train, str):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.计算SVC分类器的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-输出训练集的准确率为： 0.955555555556\n",
      "SVM-输出测试集的准确率为： 0.983333333333\n",
      "decision_function:\n",
      " [[ 2.17553848  1.24927551 -0.42481399]\n",
      " [-0.2730901   1.1358714   2.13721869]\n",
      " [-0.25602799  1.15029806  2.10572993]\n",
      " [ 2.18624735  1.26812977 -0.45437712]\n",
      " [ 2.19919365  1.26105061 -0.46024426]\n",
      " [-0.35335888  1.10838906  2.24496981]\n",
      " [ 2.19293055  1.2483294  -0.44125995]\n",
      " [-0.24361292  1.13923552  2.1043774 ]\n",
      " [-0.2706514   1.12929415  2.14135726]\n",
      " [-0.18240014  2.17368412  1.00871601]\n",
      " [-0.18389587  2.16413571  1.01976016]\n",
      " [-0.35015303  1.09779596  2.25235707]\n",
      " [-0.23267202  1.14031526  2.09235677]\n",
      " [ 2.18452015  1.24439278 -0.42891293]\n",
      " [-0.14589717  2.20794142  0.93795575]\n",
      " [-0.17079226  2.17944017  0.99135209]\n",
      " [-0.3065859   1.12927451  2.17731139]\n",
      " [-0.06205476  2.20774905  0.85430571]\n",
      " [-0.37362236  1.0823677   2.29125466]\n",
      " [-0.14294267  2.18233824  0.96060443]\n",
      " [ 2.18686871  1.25496434 -0.44183305]\n",
      " [ 2.17855402  1.26452338 -0.44307739]\n",
      " [ 2.20702107  1.24448073 -0.45150179]\n",
      " [-0.33219415  1.11021831  2.22197584]\n",
      " [ 2.19670711  1.26088004 -0.45758715]\n",
      " [-0.26224938  1.1456433   2.11660608]\n",
      " [-0.30027271  1.13764964  2.16262307]\n",
      " [-0.26014993  1.13011087  2.13003906]\n",
      " [ 2.18304597  1.25653506 -0.43958103]\n",
      " [ 2.14520848  1.24488825 -0.39009673]\n",
      " [-0.13659167  2.18900454  0.94758713]\n",
      " [ 2.17855402  1.26452338 -0.44307739]\n",
      " [-0.38722469  1.12996767  2.25725702]\n",
      " [-0.16811988  2.17595758  0.99216229]\n",
      " [-0.44040489  1.10808063  2.33232427]\n",
      " [-0.30289277  1.12569224  2.17720053]\n",
      " [-0.19854615  2.19003776  1.00850839]\n",
      " [-0.30243096  1.10123711  2.20119385]\n",
      " [-0.38551011  1.08763834  2.29787177]\n",
      " [-0.09286981  2.18525704  0.90761277]\n",
      " [ 2.19661363  1.23629047 -0.4329041 ]\n",
      " [-0.1263617   2.18843543  0.93792628]\n",
      " [ 2.16814825  1.27720231 -0.44535057]\n",
      " [-0.11800139  2.19671812  0.92128327]\n",
      " [-0.23758575  2.15995597  1.07762978]\n",
      " [ 2.16388666  1.24654692 -0.41043357]\n",
      " [-0.23189782  2.17172125  1.06017657]\n",
      " [ 2.15815478  1.23780909 -0.39596387]\n",
      " [ 2.14672438  1.24081242 -0.38753679]\n",
      " [-0.32746627  1.09423075  2.23323552]\n",
      " [-0.25240651  1.12937118  2.12303533]\n",
      " [-0.36496675  1.10263302  2.26233373]\n",
      " [ 2.18882793  1.26092681 -0.44975474]\n",
      " [ 2.18189785  1.24352928 -0.42542714]\n",
      " [-0.2248407   1.13352066  2.09132005]\n",
      " [ 2.17807288  1.25619391 -0.43426679]\n",
      " [-0.27304615  1.13284395  2.1402022 ]\n",
      " [ 2.16579579  1.25685547 -0.42265126]\n",
      " [-0.28675123  1.13152642  2.15522481]\n",
      " [-0.20090789  2.14536298  1.05554491]\n",
      " [ 2.19092514  1.25648829 -0.44741343]\n",
      " [-0.30199377  1.11259403  2.18939974]\n",
      " [ 2.22174242  1.26788639 -0.48962881]\n",
      " [-0.13764575  2.16862524  0.96902051]\n",
      " [ 2.18385484  1.26058566 -0.4444405 ]\n",
      " [-0.10390697  2.20264474  0.90126223]\n",
      " [-0.09100686  2.20968695  0.8813199 ]\n",
      " [ 2.19398687  1.25761479 -0.45160166]\n",
      " [ 2.18042144  1.26676547 -0.44718691]\n",
      " [-0.05747101  2.20348111  0.8539899 ]\n",
      " [ 2.2423342   1.2576658  -0.5       ]\n",
      " [-0.16023847  2.16481691  0.99542156]\n",
      " [-0.20969221  2.15982658  1.04986562]\n",
      " [ 2.18247079  1.25557912 -0.43804992]\n",
      " [-0.21570396  2.16211544  1.05358851]\n",
      " [-0.15183421  2.17007215  0.98176206]\n",
      " [-0.21904165  2.18179092  1.03725074]\n",
      " [-0.21197526  2.16791826  1.044057  ]\n",
      " [-0.27304615  1.13284395  2.1402022 ]\n",
      " [ 2.15791662  1.25690223 -0.41481885]\n",
      " [ 2.15987584  1.2628647  -0.42274055]\n",
      " [-0.3058772   1.14201727  2.16385994]\n",
      " [-0.14121714  2.18520603  0.95601111]\n",
      " [-0.33577392  1.13921164  2.19656228]\n",
      " [-0.08087483  2.20671608  0.87415875]\n",
      " [-0.25852068  1.15144611  2.10707457]\n",
      " [-0.30200214  1.12500656  2.17699558]\n",
      " [-0.24905396  1.16466813  2.08438584]\n",
      " [-0.34255373  1.10877588  2.23377785]\n",
      " [ 2.17855402  1.26452338 -0.44307739]]\n",
      "\n",
      "predict:\n",
      " [ 0.  2.  2.  0.  0.  2.  0.  2.  2.  1.  1.  2.  2.  0.  1.  1.  2.  1.\n",
      "  2.  1.  0.  0.  0.  2.  0.  2.  2.  2.  0.  0.  1.  0.  2.  1.  2.  2.\n",
      "  1.  2.  2.  1.  0.  1.  0.  1.  1.  0.  1.  0.  0.  2.  2.  2.  0.  0.\n",
      "  2.  0.  2.  0.  2.  1.  0.  2.  0.  1.  0.  1.  1.  0.  0.  1.  0.  1.\n",
      "  1.  0.  1.  1.  1.  1.  2.  0.  0.  2.  1.  2.  1.  2.  2.  2.  2.  0.]\n"
     ]
    }
   ],
   "source": [
    "# 方式一:\n",
    "print(\"SVM-输出训练集的准确率为：\",clf.score(x_train, y_train))  # 精度\n",
    "# 方式二:自定义准确率\n",
    "y_hat = clf.predict(x_train)\n",
    "show_accuracy(y_hat, y_train, '训练集')\n",
    "\n",
    "print(\"SVM-输出测试集的准确率为：\",clf.score(x_test, y_test))\n",
    "y_hat = clf.predict(x_test)\n",
    "show_accuracy(y_hat, y_test, '测试集')\n",
    "\n",
    "# 如果想要查看决策函数，可以通过decision_function()实现.decision_function中每一列的值代表距离各类别的距离。\n",
    "print('decision_function:\\n',clf.decision_function(x_train))\n",
    "print('\\npredict:\\n',clf.predict(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.绘制图像\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# # （1）确定坐标轴范围，x,y轴分别表示两个特征\n",
    "# x1_min, x1_max = x[:, 0].min(), x[:, 0].max()  # 第0列的范围  x[:, 0] \"：\"表示所有行，0表示第1列\n",
    "# x2_min, x2_max = x[:, 1].min(), x[:, 1].max()  # 第1列的范围  x[:, 0] \"：\"表示所有行，1表示第2列\n",
    "# x1, x2 = np.mgrid[x1_min:x1_max:200j, x2_min:x2_max:200j]  # 生成网格采样点（用meshgrid函数生成两个网格矩阵X1和X2）,可以接受两个一维数组生成两个二维矩阵\n",
    "# # meshgrid的作用是根据传入的两个一维数组参数生成两个数组元素的列表。\n",
    "# # 如果第一个参数是xarray，维度是xdimesion，第二个参数是yarray，维度是ydimesion。\n",
    "# # 那么生成的第一个二维数组是以xarray为行，ydimesion列的向量；而第二个二维数组是以yarray的转置为行，xdimesion列的向量。\n",
    "# print(x1)\n",
    "# print(x2)\n",
    "# grid_test = np.stack((x1.flat, x2.flat), axis=1)  # 测试点，再通过stack()函数，axis=1表示按垂直方向拼接，生成测试点\n",
    "# # .flat 将矩阵转变成一维数组 （与ravel()的区别：flatten：返回的是拷贝\n",
    "# print('grid_test = \\n', grid_test)\n",
    "# grid_hat = clf.predict(grid_test)  # 预测分类值\n",
    "# print(grid_hat.shape)\n",
    "# grid_hat = grid_hat.reshape(x1.shape)  # 使之与输入的形状相同  为什么要有这一步？\n",
    "# print(grid_hat)\n",
    "\n",
    "# # （2）指定默认字体\n",
    "# mpl.rcParams['font.sans-serif'] = [u'SimHei']  # 黑体 FangSong/KaiTi\n",
    "# mpl.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "\n",
    "# # (3) 绘制\n",
    "# cm_light = mpl.colors.ListedColormap(['#A0FFA0', '#FFA0A0', '#A0A0FF'])\n",
    "# cm_dark = mpl.colors.ListedColormap(['g', 'r', 'b'])\n",
    "# plt.pcolormesh(x1, x2, grid_hat, cmap=cm_light)  # pcolormesh(x,y,z,cmap)这里参数代入x1，x2，grid_hat，cmap=cm_light绘制的是背景。plt.pcolormesh()会根据grid_hat的结果自动在cmap里选择颜色\n",
    "# plt.scatter(x[:, 0], x[:, 1], c=y.ravel(), edgecolors='k', s=50, cmap=cm_dark)  # 样本  scatter中edgecolors是指描绘点的边缘色彩，s指描绘点的大小，cmap指点的颜色。\n",
    "# # 上面scatter()里面的参数传入的都是列表，所以需要的对y进行y.ravel()处理\n",
    "# print('x_test: \\n', x_test)\n",
    "# plt.scatter(x_test[:, 0], x_test[:, 1], s=120, facecolors='none', zorder=10)  # 圈中测试样本  \n",
    "# print(x1_min)\n",
    "# plt.xlim(x1_min, x1_max)  # 指图的边界\n",
    "# plt.ylim(x2_min, x2_max)\n",
    "# plt.xlabel(u'花萼长度', fontsize=13)\n",
    "# plt.ylabel(u'花萼宽度', fontsize=13)\n",
    "# plt.title(u'鸢尾花SVM二特征分类', fontsize=15)\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
